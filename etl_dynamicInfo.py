import shutil

import requests
from bs4 import BeautifulSoup
from langchain_core.documents import Document
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma
from dotenv import load_dotenv
import os

# ã€ä¿®æ­£ 1ã€‘ä¸€é–‹å§‹å°±è¼‰å…¥ç’°å¢ƒè®Šæ•¸ï¼Œé€™æ¨£å¾Œé¢çš„ OpenAIEmbeddings æ‰è®€å¾—åˆ° Key
load_dotenv()


def fetch_labor_law_docs():
    # 1. è¨­å®šç›®æ¨™ç¶²å€ (å…¨åœ‹æ³•è¦è³‡æ–™åº« - å‹å‹•åŸºæº–æ³•)
    url = "https://law.moj.gov.tw/LawClass/LawAll.aspx?PCode=N0030001"

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }

    print(f"ğŸš€ é–‹å§‹çˆ¬å–é é¢ï¼š{url} ...")
    response = requests.get(url, headers=headers)

    # å…ˆæª¢æŸ¥ç‹€æ…‹ç¢¼ï¼Œç¢ºèªæœ‰æ²’æœ‰é€£ç·šæˆåŠŸ
    print(f"ğŸ“¡ é€£ç·šç‹€æ…‹ç¢¼: {response.status_code}")

    crawled_docs = []

    if response.status_code == 200:
        print("âœ… é€£ç·šæˆåŠŸï¼é–‹å§‹è§£æ HTML...")
        soup = BeautifulSoup(response.text, "html.parser")

        # ã€é—œéµæ­¥é©Ÿ 1ã€‘é–å®šã€Œå¤§å¯¶ç®±ã€
        law_content = soup.find(class_="law-reg-content")

        if law_content:
            # ã€é—œéµæ­¥é©Ÿ 2ã€‘æ‰¾å‡ºæ¯ä¸€æ¢æ³•è¦
            all_rows = law_content.find_all(class_="row")
            print(f"ğŸ” å…±ç™¼ç¾ {len(all_rows)} å€‹æ®µè½ (åŒ…å«æ¢æ–‡èˆ‡ç« ç¯€æ¨™é¡Œ)...\n")

            for row in all_rows:
                # ã€é—œéµæ­¥é©Ÿ 3ã€‘åˆ†é›¢æ¢è™Ÿèˆ‡å…§æ–‡
                col_no = row.find(class_="col-no")
                col_data = row.find(class_="col-data")
                #BeautifulSoup æœ€å¸¸ç”¨çš„æ–¹æ³• .get_text();å®ƒæœƒæŠŠ HTML æ¨™ç±¤ï¼ˆ<div>...</div>ï¼‰ä¸Ÿæ‰ï¼Œåªç•™ä¸‹è£¡é¢çš„å­—ã€‚
                #strip=True;åŠ äº† strip=Trueï¼šå®ƒæœƒè‡ªå‹•æŠŠå‰å¾Œçš„æ›è¡Œç¬¦è™Ÿ (\n) å’Œå¤šé¤˜ç©ºç™½åˆ‡é™¤ï¼Œè®Šæˆä¹¾æ·¨çš„
                if col_no and col_data:
                    article_no = col_no.get_text(strip=True)
                    article_text = col_data.get_text(strip=True)

                    # ã€é—œéµæ­¥é©Ÿ 4ã€‘å°è£æˆ Document
                    new_doc = Document(
                        page_content=f"{article_no}ï¼š{article_text}",
                        metadata={
                            "source": "å‹å‹•åŸºæº–æ³•",
                            "url": url,
                            "article_id": article_no
                        }
                    )
                    crawled_docs.append(new_doc)

            print(f"\nğŸ“¦ æˆåŠŸè½‰æ› {len(crawled_docs)} æ¢æ³•è¦ç‚º LangChain æ–‡ä»¶ç‰©ä»¶ï¼")

            # ã€ä¿®æ­£ 2ã€‘éå¸¸é‡è¦ï¼ä¸€å®šè¦æŠŠçµæœå›å‚³å‡ºå»ï¼Œä¸ç„¶å¤–é¢æ‹¿åˆ°çš„æ˜¯ None
            return crawled_docs

        else:
            print("âŒ æ‰¾ä¸åˆ° class='law-reg-content'ï¼Œå¯èƒ½æ˜¯ç¶²é æ”¹ç‰ˆäº†ï¼Ÿ")
            return []  # å¤±æ•—æ™‚å›å‚³ç©ºåˆ—è¡¨

    else:
        print("âŒ ç¶²é è®€å–å¤±æ•—")
        return []


# å› ç‚ºä¸Šé¢å·²ç¶“ load_dotenv() äº†ï¼Œé€™è£¡å°±èƒ½å®‰å…¨å»ºç«‹ç‰©ä»¶
embedding_function = OpenAIEmbeddings(model="text-embedding-3-large")
CHROMA_PATH = "chroma_db_web_version"
if __name__ == "__main__":
    print("ğŸ•¸ï¸ é–‹å§‹çˆ¬å–æœ€æ–°æ³•è¦...")
    docs = fetch_labor_law_docs()  # æ‹¿åˆ° 98 æ¢æ³•è¦

    # é˜²å‘†æ©Ÿåˆ¶ï¼šç¢ºèªæœ‰æŠ“åˆ°è³‡æ–™æ‰å­˜
    if docs:
        # ã€æ–°å¢é€™æ®µã€‘æª¢æŸ¥ä¸¦æ¸…é™¤èˆŠè³‡æ–™åº«
        if os.path.exists(CHROMA_PATH):
            print(f"ğŸ§¹ åµæ¸¬åˆ°èˆŠè³‡æ–™åº«ï¼Œæ­£åœ¨æ¸…ç†ï¼š{CHROMA_PATH} ...")
            shutil.rmtree(CHROMA_PATH)  # å¼·åˆ¶åˆªé™¤æ•´å€‹è³‡æ–™å¤¾
            print("âœ¨ èˆŠè³‡æ–™æ¸…ç†å®Œæˆï¼")
        print(f"ğŸ’¾ é–‹å§‹å¯«å…¥å‘é‡è³‡æ–™åº« (å…± {len(docs)} ç­†)...")

        # ç›´æ¥å­˜é€² DB
        db = Chroma.from_documents(
            documents=docs,
            embedding=embedding_function,
            persist_directory="./chroma_db_web_version"
        )
        print("ğŸ‰ è³‡æ–™åº«å»ºç«‹å®Œæˆï¼è³‡æ–™å¤¾ï¼šchroma_db_web_version")
    else:
        print("âš ï¸ æ²’æœ‰æŠ“åˆ°ä»»ä½•è³‡æ–™ï¼Œç•¥éå»ºåº«æ­¥é©Ÿã€‚")