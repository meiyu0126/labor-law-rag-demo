import os
import shutil
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma
from dotenv import load_dotenv
#é€™æ”¯ç¨‹å¼é™¤äº†åˆ‡åˆ†æ–‡ä»¶(labor_law.pdf)ç‚ºç‰‡æ®µ(chunk)ä¹‹å¤–
#ä¹Ÿä½¿ç”¨ OpenAI çš„ Embedding æ¨¡å‹ (text-embedding-3-large )å°‡æ–‡å­—ç‰‡æ®µè½‰ç‚ºæ•¸å­¸å‘é‡ (Vectors)ï¼Œä¸¦å­˜å…¥ ChromaDB
#é€™æ”¯ç¨‹å¼é€šå¸¸åªéœ€è¦åœ¨è³‡æ–™æ›´æ–°æ™‚åŸ·è¡Œä¸€æ¬¡ã€‚
# 1. è¼‰å…¥ç’°å¢ƒè®Šæ•¸ (API Key)
load_dotenv()

# è¨­å®šè·¯å¾‘
FILE_PATH = os.path.join("data", "labor_law.pdf")
CHROMA_PATH = "chroma_db"  # å‘é‡è³‡æ–™åº«è¦å­˜æ”¾åœ¨å“ªå€‹è³‡æ–™å¤¾


def create_vector_db():
    # --- æ­¥é©Ÿ A: è®€å–èˆ‡åˆ‡åˆ† (è·Ÿetl.pyä¸€æ¨£) ---
    if not os.path.exists(FILE_PATH):
        print("âŒ æ‰¾ä¸åˆ° PDF æª”æ¡ˆ")
        return

    print("ğŸš€ é–‹å§‹å»ºç«‹å‘é‡è³‡æ–™åº«...")
    loader = PyPDFLoader(FILE_PATH)
    docs = loader.load()

    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,
        chunk_overlap=50,
        separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼Œ"]
    )
    chunks = text_splitter.split_documents(docs)
    print(f"ğŸ“„ å·²åˆ‡åˆ†å‡º {len(chunks)} å€‹ç‰‡æ®µã€‚")

    # --- æ­¥é©Ÿ B: æ¸…ç†èˆŠè³‡æ–™åº« (ç‚ºäº†é–‹ç™¼æ–¹ä¾¿) ---
    # å¦‚æœè³‡æ–™åº«è³‡æ–™å¤¾å·²ç¶“å­˜åœ¨ï¼Œå…ˆåˆªé™¤ï¼Œé¿å…é‡è¤‡å¡å…¥è³‡æ–™
    if os.path.exists(CHROMA_PATH):
        shutil.rmtree(CHROMA_PATH)
        print("ğŸ§¹ å·²æ¸…é™¤èˆŠçš„è³‡æ–™åº«å…§å®¹ã€‚")

    # --- æ­¥é©Ÿ C: Embedding èˆ‡ å„²å­˜ ---
    print("ğŸ§  æ­£åœ¨é€²è¡Œ Embedding (å°‡æ–‡å­—è½‰ç‚ºå‘é‡)...é€™éœ€è¦ä¸€é»æ™‚é–“...")

    # ä½¿ç”¨ OpenAI çš„ Embedding æ¨¡å‹ (text-embedding-3-large )
    embedding_function = OpenAIEmbeddings(model="text-embedding-3-large")

    # å»ºç«‹ä¸¦å„²å­˜åˆ° ChromaDB
    # é€™ä¸€æ­¥æœƒåŒæ™‚åšå…©ä»¶äº‹ï¼š1.å‘¼å«OpenAI APIè½‰å‘é‡ 2.å­˜å…¥æœ¬åœ°è³‡æ–™å¤¾
    #é€™äº›è³‡æ–™å·²ç¶“å­˜å…¥ç¡¬ç¢Ÿï¼ˆchroma_db è³‡æ–™å¤¾ï¼‰ï¼Œå³ä½¿é—œæ‰é›»è…¦ï¼Œé€™äº›è¨˜æ†¶ä¹Ÿä¸æœƒæ¶ˆå¤±ã€‚
    db = Chroma.from_documents(
        documents=chunks,
        embedding=embedding_function,
        persist_directory=CHROMA_PATH
    )

    # é€™è£¡ä¸éœ€è¦ db.persist()ï¼Œæ–°ç‰ˆ LangChain æœƒè‡ªå‹•å„²å­˜
    print(f"âœ… æˆåŠŸï¼å‘é‡è³‡æ–™åº«å·²å»ºç«‹æ–¼ '{CHROMA_PATH}' è³‡æ–™å¤¾ä¸­ã€‚")
    print(f"ğŸ“Š è³‡æ–™åº«å…§å…±æœ‰ {db._collection.count()} ç­†è³‡æ–™ã€‚")


if __name__ == "__main__":
    create_vector_db()