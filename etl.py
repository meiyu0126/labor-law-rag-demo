import os
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
#é€™æ”¯ etl.py è² è²¬ RAG ç³»çµ±çš„è³‡æ–™å‰è™•ç†;ç”¨ä¾†æ¸¬è©¦ã€Œè®€å–ã€è·Ÿã€Œåˆ‡åˆ†ã€
# é¦–å…ˆï¼Œä½¿ç”¨ PyPDFLoader å°‡éçµæ§‹åŒ–çš„ PDF è¼‰å…¥ç‚ºæ–‡ä»¶ç‰©ä»¶ã€‚
# æ¥è‘—ï¼Œæ¡ç”¨ RecursiveCharacterTextSplitter é€²è¡Œåˆ‡åˆ†ï¼Œè¨­å®š Chunk Size ç‚º 500 ä¸¦æ­é… 50 çš„ Overlapã€‚ é€™æ¨£çš„ç­–ç•¥æ˜¯ç‚ºäº†é©æ‡‰ LLM çš„ Context Window é™åˆ¶ï¼ŒåŒæ™‚é€é Overlap ä¿æŒèªæ„é€£è²«æ€§ï¼Œæœ€å¾Œä¿ç•™é ç¢¼ Metadataï¼Œä»¥æ”¯æ´å‰ç«¯çš„å¼•ç”¨ä¾†æºé¡¯ç¤ºåŠŸèƒ½ã€‚
# è¨­å®šè³‡æ–™è·¯å¾‘
FILE_PATH = os.path.join("data", "labor_law.pdf")


def load_and_split_pdf():
    # 1. æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
    if not os.path.exists(FILE_PATH):
        print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æª”æ¡ˆ {FILE_PATH}ã€‚è«‹ç¢ºèªä½ æœ‰å»ºç«‹ data è³‡æ–™å¤¾ä¸¦æ”¾å…¥ pdfã€‚")
        return

    print(f"ğŸ“‚ é–‹å§‹è®€å–æª”æ¡ˆï¼š{FILE_PATH} ...")

    # 2. è¼‰å…¥å™¨ (Loader)ï¼šè² è²¬å°‡ PDF è½‰ç‚ºç´”æ–‡å­—ç‰©ä»¶ (Document Object)
    #Extract (èƒå–)ï¼šä½¿ç”¨ LangChain å…§å»ºçš„ PyPDFLoaderå°‡ PDF è½‰ç‚ºæ–‡å­—ç‰©ä»¶
    loader = PyPDFLoader(FILE_PATH)
    docs = loader.load()
    print(f"âœ… è®€å–æˆåŠŸï¼åŸå§‹æ–‡ä»¶å…±æœ‰ {len(docs)} é ã€‚\n")

    # 3. åˆ‡åˆ†å™¨ (Splitter)ï¼šRAG çš„éˆé­‚
    # ç‚ºä»€éº¼è¦åˆ‡ï¼Ÿå› ç‚º LLM çš„ Context Window æœ‰é™ï¼Œä¸”æˆ‘å€‘å¸Œæœ›æœå°‹æ™‚èƒ½ç²¾æº–å®šä½åˆ°ã€ŒæŸå€‹æ¢æ¬¾ã€è€Œéæ•´æœ¬æ›¸ã€‚
    # chunk_size=500: æ¯å€‹å€å¡Šç´„ 500 å­— (é€™å°æ–¼æ³•è¦æ¢æ–‡ä¾†èªªé€šå¸¸åŒ…å« 1-2 æ¢å®Œæ•´æ¢æ–‡)
    # chunk_overlap=50: å‰å¾Œå€å¡Šé‡ç–Š 50 å­—ï¼Œé¿å…æŠŠä¸€å¥è©±åˆ‡æ–·åœ¨ä¸­é–“ï¼Œä¿ç•™ä¸Šä¸‹æ–‡é€£è²«æ€§ã€‚
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,
        chunk_overlap=50,
        separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", "ï¼Œ", " ", ""]  # å„ªå…ˆåœ¨æ®µè½æˆ–å¥é»è™•åˆ‡åˆ†
    )

    print("âœ‚ï¸ æ­£åœ¨é€²è¡Œæ–‡å­—åˆ‡åˆ† (Chunking)...")
    chunks = text_splitter.split_documents(docs)

    print(f"ğŸ‰ åˆ‡åˆ†å®Œæˆï¼ç¸½å…±åˆ‡å‡ºäº† {len(chunks)} å€‹ç‰‡æ®µ (Chunks)ã€‚")
    print("=" * 40)

    # 4. é©—è­‰çµæœï¼šå°å‡ºå‰ 3 å€‹ç‰‡æ®µä¾†æª¢æŸ¥å“è³ª
    #é€™è£¡è¦æª¢æŸ¥ã€Œæ¢æ–‡ã€æœ‰æ²’æœ‰è¢«ç¡¬ç”Ÿç”Ÿåˆ‡æ–·ï¼Ÿ
    for i, chunk in enumerate(chunks[:3]):
        print(f"ğŸ“„ [ç‰‡æ®µ {i + 1}] (é•·åº¦: {len(chunk.page_content)})")
        print(chunk.page_content)
        print("-" * 20)
        print(f"ä¾†æºé æ•¸: {chunk.metadata.get('page')}")  # é€™æ˜¯ Citation (å¼•ç”¨ä¾†æº) çš„åŸºç¤
        print("=" * 40)


if __name__ == "__main__":
    load_and_split_pdf()